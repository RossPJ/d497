{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNIwe5N7s0e_"
   },
   "source": [
    "# Real-world Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDYDkH-Zs7Nn"
   },
   "source": [
    "## 1. Gather data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gi6swhjSYqu2"
   },
   "source": [
    "\n",
    "\n",
    "In this project, I will be examining two datasets related to fatal helicopter accidents from 01/01/2002 to present day. From the data, I would like to understand and visualize which aircraft make and model has had the most fatal crashes and the type of aircraft that has the most fatalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AQfBAdUypMm"
   },
   "source": [
    "### **1.2.** Gather at least two datasets using two different data gathering methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e6gS0wL1KTu"
   },
   "source": [
    "#### **Dataset 1**\n",
    "\n",
    "Type: CSV File \n",
    "\n",
    "Method: The data was gathered using the \"Downloading files\" method from NTSB.org. The NTSB database was queried and produced a CSV file for download. \n",
    "\n",
    "There are many variables in this dataset. I will pick a few that are the most relevant to this project. \n",
    "\n",
    "Dataset variables:\n",
    "\n",
    "*   Variable 1 NtsbNo: specific NTSB record identification number\n",
    "*   Variable 2 AmatuerBuilt: indicates whether the aircraft was type certificated or not\n",
    "*   Variable 3 Make: this is the manufacturer of the helicopter (e.g  Bell, Boeing, Airbus, Sikorsky)\n",
    "*   Variable 4 Model: this is the specific model of helicopter from the manufacturer (e.g 505, R44, EC120, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Su8E0uLuYkHU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NtsbNo', 'EventType', 'Mkey', 'EventDate', 'City', 'State', 'Country',\n",
       "       'ReportNo', 'N', 'HasSafetyRec', 'ReportType', 'OriginalPublishDate',\n",
       "       'HighestInjuryLevel', 'FatalInjuryCount', 'SeriousInjuryCount',\n",
       "       'MinorInjuryCount', 'ProbableCause', 'EventID', 'Latitude', 'Longitude',\n",
       "       'Make', 'Model', 'AirCraftCategory', 'AirportID', 'AirportName',\n",
       "       'AmateurBuilt', 'NumberOfEngines', 'Scheduled', 'PurposeOfFlight',\n",
       "       'FAR', 'AirCraftDamage', 'WeatherCondition', 'Operator', 'ReportStatus',\n",
       "       'RepGenFlag', 'DocketUrl', 'DocketPublishDate', 'Unnamed: 37'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FILL IN 1st data gathering and loading method\n",
    "df_csv = pd.read_csv(\"helicopter_crash_data.csv\")\n",
    "df_csv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoUjq1tPzz7P"
   },
   "source": [
    "#### Dataset 2\n",
    "\n",
    "Type: JSON File\n",
    "\n",
    "Method: The data was gathered using the \"Downloading files\" method from NTSB.org. The NTSB database was queried and produced a JSON file for download. \n",
    "\n",
    "There are many variables in this dataset. I will pick a few that are the most relevant to this project. \n",
    "\n",
    "Dataset variables:\n",
    "\n",
    "*   Variable 1 HighestInjuryLevel: fatality for this analysis.\n",
    "*   Variable 2 City: city where accident took place\n",
    "*   Variable 3 State: state where accident took place \n",
    "*   Variable 4 Country: country where accident took place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6zT0QxRyYmm7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Oid', 'MKey', 'Closed', 'CompletionStatus', 'HasSafetyRec',\n",
       "       'HighestInjury', 'IsStudy', 'Mode', 'NtsbNumber',\n",
       "       'OriginalPublishedDate', 'MostRecentReportType', 'ProbableCause',\n",
       "       'City', 'Country', 'EventDate', 'State', 'Agency', 'BoardLaunch',\n",
       "       'BoardMeetingDate', 'DocketDate', 'EventType', 'Launch', 'ReportDate',\n",
       "       'ReportNum', 'ReportType', 'Vehicles', 'AirportId', 'AirportName',\n",
       "       'AnalysisNarrative', 'FactualNarrative', 'PrelimNarrative',\n",
       "       'FatalInjuryCount', 'MinorInjuryCount', 'SeriousInjuryCount',\n",
       "       'InvestigationClass', 'AccidentSiteCondition', 'Latitude', 'Longitude',\n",
       "       'DocketOriginalPublishDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FILL IN 2nd data gathering and loading method\n",
    "df_json = pd.read_json(\"helicopter_crash_data.json\")\n",
    "df_json.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwSWIVmotLgV"
   },
   "source": [
    "## 2. Assess data\n",
    "\n",
    "Assess the data according to data quality and tidiness metrics using the report below.\n",
    "\n",
    "List **two** data quality issues and **two** tidiness issues. Assess each data issue visually **and** programmatically, then briefly describe the issue you find.  **Make sure you include justifications for the methods you use for the assessment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adaK2iPNzVu4"
   },
   "source": [
    "### Quality Issue 1:\n",
    "\n",
    "Uniqueness \n",
    "\n",
    "There are multiple rows in the dataframe df_csv where the Column of \"N\" does not contain a unique value. There are multiple aircraft per cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "SpW59kh-zl8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     OE-XOS, ES-ETR\n",
       "1             N216MH\n",
       "2              N23SD\n",
       "3             N331ES\n",
       "4             N262LH\n",
       "5             N835CS\n",
       "6             N144SG\n",
       "7             N118LG\n",
       "8             D-HSEP\n",
       "9             PK-LUV\n",
       "10            ZS-RAC\n",
       "11            HC-CQY\n",
       "12     N709PS, UNREG\n",
       "13            PR-TIB\n",
       "14            N622LT\n",
       "15            N617GC\n",
       "16            N368EV\n",
       "17             N62CD\n",
       "18            N881KE\n",
       "19            N230AE\n",
       "20            EC-EXE\n",
       "21            N306FW\n",
       "22            N199BD\n",
       "23            VH-ERH\n",
       "24            9N-AJD\n",
       "25            TG-MIC\n",
       "26             N94XA\n",
       "27            N61486\n",
       "28    VH-HQH, VH-HYQ\n",
       "Name: N, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FILL IN - Inspecting the dataframe visually\n",
    "#inspecting the dataframe visually with the .head() method because the dataframe is too large to view in this notebook. \n",
    "#The first issue we can see is that there are some rows that have multiple values in some cells - uniqueness issue. (example, column \"N\" has multiple aircraft in the cell)\n",
    "#I would like to drop these rows and focus on accidents only involving one aircraft.\n",
    "#If time permitted, I would normalize the data and create 2 unique rows from the rows where multpiple aircraft are involved. \n",
    "df_csv['N'].head(29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-qfcocStzsKg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N\n",
       "False    686\n",
       "True      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FILL IN - Inspecting the dataframe programmatically\n",
    "\n",
    "#For the column df_csv['N'], we can see that there are 16 rows where there are multiple aircraft involved. \n",
    "df_csv['N'].str.contains(',', na=False).value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: \n",
    "\n",
    "Having two aircraft listed in a single cell value—often separated by a comma—can be problematic when analyzing a dataset. This makes it difficult to accurately filter, group, or analyze aircraft-specific data, such as counting incidents by aircraft type or correlating characteristics with outcomes. To ensure clean and meaningful analysis, such entries should be split into separate rows or normalized into a relational structure. Removing the rows where two aircraft are listed will suffice for this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Be77N4I1AmE"
   },
   "source": [
    "### Quality Issue 2:\n",
    "\n",
    "Completeness\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMhHyiyLM2I3"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnviRCUI-bb7"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXhGiYyiwwKN"
   },
   "source": [
    "### Tidiness Issue 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fleC5rORI0Xl"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTuQw7Rbsio4"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ffMoRGSwzYj"
   },
   "source": [
    "### Tidiness Issue 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUpeoqokw5Qt"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8JK4DoXxtFA"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6gmLnBttpCh"
   },
   "source": [
    "## 3. Clean data\n",
    "Clean the data to solve the 4 issues corresponding to data quality and tidiness found in the assessing step. **Make sure you include justifications for your cleaning decisions.**\n",
    "\n",
    "After the cleaning for each issue, please use **either** the visually or programatical method to validate the cleaning was succesful.\n",
    "\n",
    "At this stage, you are also expected to remove variables that are unnecessary for your analysis and combine your datasets. Depending on your datasets, you may choose to perform variable combination and elimination before or after the cleaning stage. Your dataset must have **at least** 4 variables after combining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - Make copies of the datasets to ensure the raw dataframes \n",
    "# are not impacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmFhN52Yyn3l"
   },
   "source": [
    "### **Quality Issue 1: FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UejDWrNMW4a"
   },
   "outputs": [],
   "source": [
    "# FILL IN - Apply the cleaning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUBee-LPytkv"
   },
   "outputs": [],
   "source": [
    "# FILL IN - Validate the cleaning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_DAUbJrymBL"
   },
   "source": [
    "### **Quality Issue 2: FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Yfb-Yu5MTuE"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Apply the cleaning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ionB2sRaMUmY"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Validate the cleaning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIUrrfSNyOPR"
   },
   "source": [
    "### **Tidiness Issue 1: FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fib0zAm333bn"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Apply the cleaning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhrnUGY_Nk8B"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Validate the cleaning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o51Bt8kwyTzk"
   },
   "source": [
    "### **Tidiness Issue 2: FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7zW8O5yx4Y9O"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Apply the cleaning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q6I_Sr7lxXi5"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Validate the cleaning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove unnecessary variables and combine datasets**\n",
    "\n",
    "Depending on the datasets, you can also peform the combination before the cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL IN - Remove unnecessary variables and combine datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F42urHuzttjF"
   },
   "source": [
    "## 4. Update your data store\n",
    "Update your local database/data store with the cleaned data, following best practices for storing your cleaned data:\n",
    "\n",
    "- Must maintain different instances / versions of data (raw and cleaned data)\n",
    "- Must name the dataset files informatively\n",
    "- Ensure both the raw and cleaned data is saved to your database/data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3uay7EJUV_L"
   },
   "outputs": [],
   "source": [
    "#FILL IN - saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGy_yddGtzhM"
   },
   "source": [
    "## 5. Answer the research question\n",
    "\n",
    "### **5.1:** Define and answer the research question \n",
    "Going back to the problem statement in step 1, use the cleaned data to answer the question you raised. Produce **at least** two visualizations using the cleaned data and explain how they help you answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjedE4s4ZkEd"
   },
   "source": [
    "*Research question:* FILL IN from answer to Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lkw3rW9kZmOm"
   },
   "outputs": [],
   "source": [
    "#Visual 1 - FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to research question:* FILL IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fdK_8ZGZm9R"
   },
   "outputs": [],
   "source": [
    "#Visual 2 - FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5RgvMGUZoHn"
   },
   "source": [
    "*Answer to research question:* FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ezWXXZVj-TP"
   },
   "source": [
    "### **5.2:** Reflection\n",
    "In 2-4 sentences, if you had more time to complete the project, what actions would you take? For example, which data quality and structural issues would you look into further, and what research questions would you further explore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB3RBDG5kFe1"
   },
   "source": [
    "*Answer:* FILL IN"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
